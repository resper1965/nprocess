# Google AI Stack Architecture üöÄ

**ComplianceEngine Platform - 100% Google Cloud + Vertex AI**

---

## üéØ Vis√£o Geral

O **ComplianceEngine Platform** √© constru√≠do **exclusivamente** sobre o ecossistema **Google Cloud Platform (GCP)** e **Google AI (Vertex AI)**, aproveitando todo o portf√≥lio de modelos Gemini e servi√ßos de IA.

### Por que 100% Google AI?

‚úÖ **Integra√ß√£o Nativa**: Todos os servi√ßos GCP integram nativamente
‚úÖ **Vertex AI Unified**: Plataforma √∫nica para treino, deploy e monitoramento
‚úÖ **Multimodal**: Gemini processa texto, c√≥digo, imagens, diagramas
‚úÖ **Escalabilidade**: Auto-scaling nativo no Cloud Run
‚úÖ **Custo-benef√≠cio**: Pre√ßos competitivos + billing unificado
‚úÖ **Compliance**: Certifica√ß√µes Google (ISO 27001, SOC2, LGPD-ready)

---

## üß† Portf√≥lio Gemini - Quando Usar Cada Modelo

### 1. **Gemini 1.5 Flash** (Recomendado para Produ√ß√£o)

**Caracter√≠sticas**:
- ‚ö° **Mais r√°pido**: ~2x velocidade vs Pro
- üí∞ **Mais barato**: ~50% custo vs Pro
- üìä **Context window**: 1M tokens
- üéØ **Ideal para**: Tarefas frequentes, alta throughput

**Uso no ComplianceEngine**:
```python
# compliance-engine-api/app/services/ai_service.py
from vertexai.generative_models import GenerativeModel

# Para gera√ß√£o de BPMN (tarefa frequente)
flash_model = GenerativeModel("gemini-1.5-flash-002")

async def generate_bpmn_fast(description: str) -> dict:
    """Gera√ß√£o r√°pida de BPMN usando Flash"""
    prompt = f"""Gere um diagrama BPMN em formato Mermaid...
    Descri√ß√£o: {description}
    """
    response = await flash_model.generate_content_async(prompt)
    return parse_bpmn_response(response.text)
```

**Onde usar**:
- ‚úÖ Gera√ß√£o de BPMN de descri√ß√µes naturais
- ‚úÖ Mapeamento de controles (ISO, SOC2, CIS)
- ‚úÖ Convers√£o BPMN ‚Üí Mermaid
- ‚úÖ Normaliza√ß√£o de texto de processos
- ‚úÖ Classifica√ß√£o de documentos regulat√≥rios

### 2. **Gemini 1.5 Pro** (Para An√°lises Complexas)

**Caracter√≠sticas**:
- üß† **Mais inteligente**: Racioc√≠nio complexo
- üìö **Context window**: 2M tokens
- üî¨ **Ideal para**: An√°lises profundas, compliance gaps

**Uso no ComplianceEngine**:
```python
# Para an√°lise de compliance (tarefa complexa)
pro_model = GenerativeModel("gemini-1.5-pro-002")

async def analyze_compliance_gaps(bpmn_xml: str, framework: str) -> dict:
    """An√°lise profunda de gaps de conformidade"""
    # Recupera regula√ß√µes via RAG
    regulations = await retrieve_regulations(framework)

    prompt = f"""Analise o processo BPMN contra {framework}.

    BPMN: {bpmn_xml}

    Regula√ß√µes aplic√°veis:
    {regulations}

    Identifique:
    1. Gaps cr√≠ticos de conformidade
    2. Severidade de cada gap
    3. Recomenda√ß√µes de remedia√ß√£o espec√≠ficas
    4. Controles faltantes
    """

    response = await pro_model.generate_content_async(
        prompt,
        generation_config={
            "temperature": 0.1,  # Precis√£o m√°xima
            "top_p": 0.95,
            "max_output_tokens": 8192
        }
    )
    return parse_compliance_analysis(response.text)
```

**Onde usar**:
- ‚úÖ An√°lise de gaps de conformidade (LGPD, ISO 27001)
- ‚úÖ Avalia√ß√£o de necessidade de DPIA
- ‚úÖ An√°lise de riscos (likelihood, impact)
- ‚úÖ Gera√ß√£o de ROPA completo (lifecycle analysis)
- ‚úÖ Recomenda√ß√µes de medidas compensat√≥rias (ONS)

### 3. **Gemini 2.0 Flash** (Experimental - Multimodal Avan√ßado)

**Caracter√≠sticas**:
- üé® **Multimodal nativo**: Texto + imagem + √°udio
- üöÄ **Pr√≥xima gera√ß√£o**: Lan√ßamento recente
- üî• **Performance**: Flash speed + Pro capabilities

**Uso futuro no ComplianceEngine**:
```python
# Planejado: An√°lise de diagramas BPMN em imagem
gemini_2_flash = GenerativeModel("gemini-2.0-flash-exp")

async def analyze_bpmn_image(image_path: str) -> dict:
    """Converte diagrama BPMN em imagem para XML"""
    from vertexai.generative_models import Part

    image = Part.from_uri(image_path, mime_type="image/png")

    prompt = """Analise este diagrama BPMN e converta para:
    1. XML BPMN 2.0 v√°lido
    2. Lista de tasks, gateways, events
    3. Sequence flows
    """

    response = await gemini_2_flash.generate_content_async([image, prompt])
    return parse_bpmn_from_image(response.text)
```

**Casos de uso futuros**:
- üì∏ Upload de foto de whiteboard ‚Üí BPMN XML
- üìÑ OCR de documentos regulat√≥rios (PDFs escaneados)
- üéôÔ∏è Transcri√ß√£o de entrevistas de operadores (OT2net)

### 4. **Gemini Nano** (Edge Computing)

**Caracter√≠sticas**:
- üì± **On-device**: Roda em dispositivo local
- üîí **Privacy-first**: Dados n√£o saem do dispositivo
- ‚ö° **Lat√™ncia zero**: Sem chamada de rede

**Uso em Aplica√ß√µes Consumidoras**:
```typescript
// n.privacy App - Cliente web com Gemini Nano
// Via Chrome Built-in AI (Gemini Nano)

// Exemplo: Valida√ß√£o local de descri√ß√£o ROPA
const session = await ai.languageModel.create({
  systemPrompt: "Voc√™ valida descri√ß√µes de processos de dados LGPD."
});

async function validateROPADescription(description: string): Promise<boolean> {
  const response = await session.prompt(`
    Valide se esta descri√ß√£o tem informa√ß√µes suficientes para ROPA:
    "${description}"

    Responda apenas: COMPLETO ou INCOMPLETO (motivo)
  `);

  return response.startsWith("COMPLETO");
}

// S√≥ envia para ComplianceEngine (backend) se valida√ß√£o passar
if (await validateROPADescription(userInput)) {
  // Chamada MCP ao motor
  await mcpClient.callTool("generate_bpmn", { description: userInput });
}
```

**Benef√≠cios**:
- ‚úÖ Feedback instant√¢neo ao usu√°rio (sem lat√™ncia de rede)
- ‚úÖ Reduz chamadas desnecess√°rias ao backend
- ‚úÖ Privacidade: dados sens√≠veis n√£o trafegam em pr√©-valida√ß√£o
- ‚úÖ Economia de custos (menos chamadas Vertex AI)

---

## üèóÔ∏è Arquitetura GCP Completa

### Camada de IA (Vertex AI)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Vertex AI Platform                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ  ‚îÇ Gemini 1.5 Flash ‚îÇ  ‚îÇ Gemini 1.5 Pro   ‚îÇ           ‚îÇ
‚îÇ  ‚îÇ (Gera√ß√£o BPMN)   ‚îÇ  ‚îÇ (An√°lise Gaps)   ‚îÇ           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Vertex AI Search                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (Discovery Engine - RAG Regulat√≥rio)            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - ANEEL corpus                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - ONS corpus                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - LGPD corpus                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - BACEN/CVM/SUSEP corpus                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Vertex AI Embeddings                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (text-embedding-004)                            ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Embedding de regula√ß√µes para search          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Similarity search                             ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Camada de Dados (Cloud Storage + Firestore)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Google Cloud Storage                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üì¶ compliance-regulations-bucket/                      ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ aneel/                                          ‚îÇ
‚îÇ     ‚îÇ   ‚îú‚îÄ‚îÄ resolucoes-normativas/                     ‚îÇ
‚îÇ     ‚îÇ   ‚îî‚îÄ‚îÄ notas-tecnicas/                            ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ ons/                                            ‚îÇ
‚îÇ     ‚îÇ   ‚îî‚îÄ‚îÄ procedimentos-rede/                        ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ lgpd/                                           ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ bacen/                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Cloud Firestore (NoSQL)                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üìÇ Collections:                                        ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ frameworks/          (ISO, SOC2, CIS metadata) ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ templates/           (Jinja2 templates)        ‚îÇ
‚îÇ     ‚îú‚îÄ‚îÄ crawl_history/       (Regulatory updates)      ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ cache/               (Temporary processing)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Camada de Compute (Cloud Run)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Google Cloud Run (Serverless)              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                         ‚îÇ
‚îÇ  üîß compliance-engine-api          (Python/FastAPI)    ‚îÇ
‚îÇ     - Auto-scaling: 0 ‚Üí 100 instances                  ‚îÇ
‚îÇ     - Memory: 2Gi, CPU: 2                              ‚îÇ
‚îÇ     - Gemini 1.5 Flash + Pro                           ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  üîç regulatory-rag-api             (Python/FastAPI)    ‚îÇ
‚îÇ     - Vertex AI Search integration                     ‚îÇ
‚îÇ     - Embedding API                                    ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  üï∑Ô∏è regulatory-crawler             (Python/FastAPI)    ‚îÇ
‚îÇ     - Scheduled via Cloud Scheduler                    ‚îÇ
‚îÇ     - Gemini Pro for analysis                          ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  üìÑ document-generator             (Python/FastAPI)    ‚îÇ
‚îÇ     - Jinja2 + Mermaid rendering                       ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  üé® admin-dashboard                (Next.js)           ‚îÇ
‚îÇ     - Static site on Cloud Run                         ‚îÇ
‚îÇ                                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Camada de Integra√ß√£o (MCP Gateway)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MCP HTTP Gateway (Cloud Run)               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üåê HTTP ‚Üí MCP STDIO Bridge                            ‚îÇ
‚îÇ     - WebSocket support                                 ‚îÇ
‚îÇ     - SSE (Server-Sent Events)                         ‚îÇ
‚îÇ     - Auth: Google Identity Platform                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üí∞ Otimiza√ß√£o de Custos - Escolha Inteligente de Modelos

### Matriz de Decis√£o: Flash vs Pro

| Tarefa | Modelo | Justificativa | Custo/1M tokens |
|--------|--------|---------------|-----------------|
| Gerar BPMN simples | **Flash** | Tarefa estruturada, alta frequ√™ncia | $0.075 |
| Normalizar texto | **Flash** | Transforma√ß√£o determin√≠stica | $0.075 |
| Converter BPMN‚ÜíMermaid | **Flash** | Sintaxe bem definida | $0.075 |
| Classificar documentos | **Flash** | Categoriza√ß√£o simples | $0.075 |
| **Analisar compliance gaps** | **Pro** | Racioc√≠nio complexo, contextual | $1.25 |
| **Avaliar DPIA** | **Pro** | An√°lise de riscos profunda | $1.25 |
| **Medidas compensat√≥rias ONS** | **Pro** | Requer conhecimento regulat√≥rio | $1.25 |
| **An√°lise de seguran√ßa LGPD** | **Pro** | Compliance cr√≠tico | $1.25 |

### Exemplo de Economia

**Cen√°rio**: 1000 gera√ß√µes de BPMN/dia

```python
# ‚ùå Usando Pro para tudo (custo alto)
tokens_per_request = 5000  # avg
requests_per_day = 1000
cost_pro = (tokens_per_request * requests_per_day / 1_000_000) * 1.25
# = $6.25/dia = $187.50/m√™s

# ‚úÖ Usando Flash para BPMN (custo otimizado)
cost_flash = (tokens_per_request * requests_per_day / 1_000_000) * 0.075
# = $0.375/dia = $11.25/m√™s

# üí∞ Economia: $176.25/m√™s (94% redu√ß√£o!)
```

---

## üîß Configura√ß√£o Vertex AI - Best Practices

### 1. Inicializa√ß√£o do SDK

```python
# compliance-engine-api/app/services/vertex_ai_service.py
import vertexai
from vertexai.generative_models import GenerativeModel, Part
from google.cloud import aiplatform

# Inicializa√ß√£o (executar no startup do FastAPI)
def init_vertex_ai():
    """Inicializa Vertex AI com projeto e regi√£o"""
    PROJECT_ID = os.getenv("GOOGLE_CLOUD_PROJECT")
    REGION = os.getenv("VERTEX_AI_REGION", "us-central1")

    vertexai.init(project=PROJECT_ID, location=REGION)

    # Tamb√©m inicializa aiplatform (para features avan√ßadas)
    aiplatform.init(project=PROJECT_ID, location=REGION)

    logger.info(f"Vertex AI initialized: {PROJECT_ID} @ {REGION}")

# Chamar no startup
@app.on_event("startup")
async def startup_event():
    init_vertex_ai()
```

### 2. Pooling de Modelos (Performance)

```python
# Singleton pattern para modelos Gemini
class GeminiModelPool:
    _flash_model: GenerativeModel = None
    _pro_model: GenerativeModel = None

    @classmethod
    def get_flash(cls) -> GenerativeModel:
        """Retorna inst√¢ncia singleton do Flash"""
        if cls._flash_model is None:
            cls._flash_model = GenerativeModel(
                "gemini-1.5-flash-002",
                system_instruction=[
                    "Voc√™ √© um especialista em BPMN e compliance.",
                    "Sempre retorne JSON v√°lido.",
                    "Use portugu√™s brasileiro."
                ]
            )
        return cls._flash_model

    @classmethod
    def get_pro(cls) -> GenerativeModel:
        """Retorna inst√¢ncia singleton do Pro"""
        if cls._pro_model is None:
            cls._pro_model = GenerativeModel(
                "gemini-1.5-pro-002",
                system_instruction=[
                    "Voc√™ √© um auditor de compliance certificado.",
                    "An√°lises devem ser precisas e baseadas em fatos.",
                    "Cite sempre artigos e controles espec√≠ficos."
                ]
            )
        return cls._pro_model

# Uso
flash = GeminiModelPool.get_flash()
response = await flash.generate_content_async(prompt)
```

### 3. Rate Limiting e Retry (Resili√™ncia)

```python
from tenacity import retry, stop_after_attempt, wait_exponential
from google.api_core import exceptions as google_exceptions

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10),
    retry=retry_if_exception_type((
        google_exceptions.ResourceExhausted,  # Quota exceeded
        google_exceptions.ServiceUnavailable,  # 503
        google_exceptions.DeadlineExceeded     # Timeout
    ))
)
async def generate_with_retry(model: GenerativeModel, prompt: str) -> str:
    """Gera√ß√£o com retry autom√°tico em caso de falha"""
    try:
        response = await model.generate_content_async(
            prompt,
            generation_config={
                "temperature": 0.1,
                "max_output_tokens": 8192
            }
        )
        return response.text
    except google_exceptions.InvalidArgument as e:
        # Prompt inv√°lido - n√£o fazer retry
        logger.error(f"Invalid prompt: {e}")
        raise
    except Exception as e:
        logger.warning(f"Gemini API error, retrying: {e}")
        raise
```

### 4. Streaming para UX Melhor

```python
# Para respostas longas (an√°lise de gaps)
async def analyze_compliance_streaming(bpmn_xml: str, framework: str):
    """Streaming de an√°lise de compliance para UI"""
    pro = GeminiModelPool.get_pro()

    prompt = f"Analise o processo contra {framework}:\n{bpmn_xml}"

    # Streaming response
    async for chunk in pro.generate_content_async(
        prompt,
        stream=True
    ):
        if chunk.text:
            yield f"data: {chunk.text}\n\n"  # SSE format

    yield "data: [DONE]\n\n"

# FastAPI endpoint
@app.get("/v1/compliance/analyze-stream/{process_id}")
async def analyze_stream(process_id: str):
    """Endpoint com streaming via SSE"""
    process = await get_process(process_id)

    return StreamingResponse(
        analyze_compliance_streaming(process.bpmn_xml, process.framework),
        media_type="text/event-stream"
    )
```

---

## üîç Vertex AI Search (RAG Regulat√≥rio)

### Arquitetura do Corpus Regulat√≥rio

```
Vertex AI Search Data Store: "compliance-regulations"
‚îú‚îÄ‚îÄ ANEEL Collection
‚îÇ   ‚îú‚îÄ‚îÄ Document: "REN_1050_2024.pdf"
‚îÇ   ‚îú‚îÄ‚îÄ Document: "REN_964_2021.pdf"
‚îÇ   ‚îî‚îÄ‚îÄ ... (500+ documentos)
‚îú‚îÄ‚îÄ ONS Collection
‚îÇ   ‚îú‚îÄ‚îÄ Document: "Procedimento_Rede_Subm√≥dulo_2.1.pdf"
‚îÇ   ‚îî‚îÄ‚îÄ ... (200+ documentos)
‚îú‚îÄ‚îÄ LGPD Collection
‚îÇ   ‚îú‚îÄ‚îÄ Document: "Lei_13709_2018.pdf"
‚îÇ   ‚îú‚îÄ‚îÄ Document: "ANPD_Guia_Agentes.pdf"
‚îÇ   ‚îî‚îÄ‚îÄ ... (50+ documentos)
‚îî‚îÄ‚îÄ BACEN/CVM/SUSEP Collections
```

### Implementa√ß√£o Search API

```python
# regulatory-rag-api/app/services/vertex_search_service.py
from google.cloud import discoveryengine_v1 as discoveryengine

class VertexSearchService:
    def __init__(self):
        self.client = discoveryengine.SearchServiceClient()
        self.project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
        self.location = "global"
        self.data_store_id = "compliance-regulations"

    async def search_by_datasets(
        self,
        query: str,
        datasets: list[str],  # ["aneel", "ons", "ans", "lgpd"]
        max_results: int = 5
    ) -> list[dict]:
        """Busca filtrada por datasets"""

        # Construir filter expression
        # Exemplo: "source:aneel OR source:ons"
        filter_expr = " OR ".join([f"source:{ds}" for ds in datasets])

        serving_config = (
            f"projects/{self.project_id}/locations/{self.location}/"
            f"collections/default_collection/dataStores/{self.data_store_id}/"
            f"servingConfigs/default_config"
        )

        request = discoveryengine.SearchRequest(
            serving_config=serving_config,
            query=query,
            page_size=max_results,
            filter=filter_expr,
            # Boost relevance
            query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(
                condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO
            ),
            # Spell correction
            spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(
                mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO
            )
        )

        response = self.client.search(request)

        results = []
        for result in response.results:
            doc = result.document.derived_struct_data
            results.append({
                "id": result.document.id,
                "title": doc.get("title", ""),
                "source": doc.get("source", ""),
                "snippet": doc.get("snippet", ""),
                "link": doc.get("link", ""),
                "relevance_score": result.relevance_score
            })

        return results
```

### Ingest√£o de Documentos no Vertex AI Search

```python
# Script de ingest√£o
from google.cloud import discoveryengine_v1 as discoveryengine

async def ingest_aneel_documents():
    """Ingere documentos ANEEL no Vertex AI Search"""
    client = discoveryengine.DocumentServiceClient()

    parent = (
        f"projects/{PROJECT_ID}/locations/global/"
        f"collections/default_collection/dataStores/compliance-regulations/branches/default_branch"
    )

    # Exemplo: Upload de Resolu√ß√£o Normativa
    document = discoveryengine.Document(
        id="aneel_ren_1050_2024",
        struct_data={
            "title": "Resolu√ß√£o Normativa n¬∫ 1.050/2024",
            "source": "aneel",
            "type": "resolucao_normativa",
            "year": 2024,
            "number": "1050",
            "subject": "Ciberseguran√ßa no Setor El√©trico",
            "full_text": "... texto completo da resolu√ß√£o ...",
            "link": "https://www2.aneel.gov.br/cedoc/ren20241050.pdf"
        },
        content=discoveryengine.Document.Content(
            mime_type="application/pdf",
            uri=f"gs://compliance-regulations-bucket/aneel/ren_1050_2024.pdf"
        )
    )

    request = discoveryengine.CreateDocumentRequest(
        parent=parent,
        document=document,
        document_id=document.id
    )

    response = client.create_document(request=request)
    logger.info(f"Document ingested: {response.name}")
```

---

## üìä Monitoring e Observability (Cloud Operations)

### Cloud Logging Integration

```python
# Logging estruturado para Vertex AI calls
import google.cloud.logging
from google.cloud.logging_v2.handlers import CloudLoggingHandler

# Setup
logging_client = google.cloud.logging.Client()
handler = CloudLoggingHandler(logging_client, name="compliance-engine")

logger = logging.getLogger("vertex-ai-calls")
logger.setLevel(logging.INFO)
logger.addHandler(handler)

# Log de chamadas Gemini
async def generate_with_logging(model_name: str, prompt: str, **kwargs):
    start_time = time.time()

    try:
        response = await model.generate_content_async(prompt, **kwargs)

        duration = time.time() - start_time

        # Log estruturado
        logger.info(
            "Gemini API call successful",
            extra={
                "model": model_name,
                "prompt_tokens": len(prompt.split()),
                "response_tokens": len(response.text.split()),
                "duration_ms": duration * 1000,
                "status": "success"
            }
        )

        return response.text

    except Exception as e:
        logger.error(
            "Gemini API call failed",
            extra={
                "model": model_name,
                "error": str(e),
                "status": "error"
            }
        )
        raise
```

### Custom Metrics (Cloud Monitoring)

```python
from google.cloud import monitoring_v3
import time

class VertexAIMetrics:
    def __init__(self):
        self.client = monitoring_v3.MetricServiceClient()
        self.project_name = f"projects/{PROJECT_ID}"

    def record_gemini_latency(self, model: str, latency_ms: float):
        """Registra lat√™ncia de chamada Gemini"""
        series = monitoring_v3.TimeSeries()
        series.metric.type = "custom.googleapis.com/gemini/latency"
        series.metric.labels["model"] = model

        now = time.time()
        seconds = int(now)
        nanos = int((now - seconds) * 10**9)

        interval = monitoring_v3.TimeInterval(
            {"end_time": {"seconds": seconds, "nanos": nanos}}
        )

        point = monitoring_v3.Point({
            "interval": interval,
            "value": {"double_value": latency_ms}
        })

        series.points = [point]
        self.client.create_time_series(
            name=self.project_name,
            time_series=[series]
        )
```

---

## üöÄ Deploy Otimizado para GCP

### Cloud Run - Configura√ß√£o Recomendada

```yaml
# cloud-run-config.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: compliance-engine-api
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: "1"  # Warm instance
        autoscaling.knative.dev/maxScale: "100"
        run.googleapis.com/cpu-throttling: "false"  # Always allocated CPU
        run.googleapis.com/startup-cpu-boost: "true"  # Faster cold start
    spec:
      serviceAccountName: compliance-engine-sa@PROJECT_ID.iam.gserviceaccount.com
      containers:
      - image: gcr.io/PROJECT_ID/compliance-engine:latest
        resources:
          limits:
            cpu: "2000m"
            memory: "2Gi"
        env:
        - name: GOOGLE_CLOUD_PROJECT
          value: "PROJECT_ID"
        - name: VERTEX_AI_REGION
          value: "us-central1"
        - name: GEMINI_FLASH_MODEL
          value: "gemini-1.5-flash-002"
        - name: GEMINI_PRO_MODEL
          value: "gemini-1.5-pro-002"
```

### Service Account Permissions

```bash
# Criar service account
gcloud iam service-accounts create compliance-engine-sa \
  --display-name="ComplianceEngine Service Account"

# Vertex AI User (Gemini access)
gcloud projects add-iam-policy-binding PROJECT_ID \
  --member="serviceAccount:compliance-engine-sa@PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/aiplatform.user"

# Firestore User
gcloud projects add-iam-policy-binding PROJECT_ID \
  --member="serviceAccount:compliance-engine-sa@PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/datastore.user"

# Cloud Storage Object Viewer (para regula√ß√µes)
gcloud projects add-iam-policy-binding PROJECT_ID \
  --member="serviceAccount:compliance-engine-sa@PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/storage.objectViewer"

# Discovery Engine Editor (Vertex AI Search)
gcloud projects add-iam-policy-binding PROJECT_ID \
  --member="serviceAccount:compliance-engine-sa@PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/discoveryengine.editor"
```

---

## üéØ Roadmap Google AI

### Curto Prazo (Q1 2025)

- ‚úÖ **Gemini 1.5 Flash** para todas as tarefas frequentes
- ‚úÖ **Gemini 1.5 Pro** para an√°lises complexas
- ‚è≥ **Vertex AI Search** com datasets segregados (ANEEL, ONS, ANS, LGPD, CVM, BACEN, SUSEP, ARCyber)
- ‚è≥ **Embeddings API** (text-embedding-004) para similarity search

### M√©dio Prazo (Q2 2025)

- üîú **Gemini 2.0 Flash** (multimodal) para an√°lise de diagramas
- üîú **Vertex AI Agent Builder** para workflows complexos
- üîú **Cloud Functions Gen 2** para processamento ass√≠ncrono
- üîú **Gemini Code Assist** para gera√ß√£o de c√≥digo BPMN

### Longo Prazo (Q3-Q4 2025)

- üîÆ **Gemini Nano** em aplica√ß√µes consumidoras (edge computing)
- üîÆ **Vertex AI Pipelines** para treino de modelos custom
- üîÆ **Model Garden** para fine-tuning em regula√ß√µes brasileiras
- üîÆ **Gemini Ultra** para casos cr√≠ticos de auditoria

---

## üí° Best Practices - Google AI

### 1. **Sempre use system instructions**
```python
model = GenerativeModel(
    "gemini-1.5-flash-002",
    system_instruction=[
        "Voc√™ √© um especialista em compliance brasileiro.",
        "Sempre cite fontes (ANEEL, LGPD, ISO).",
        "Retorne JSON v√°lido quando solicitado."
    ]
)
```

### 2. **Temperature baixo para compliance**
```python
generation_config = {
    "temperature": 0.1,  # M√°xima precis√£o
    "top_p": 0.95,
    "top_k": 40
}
```

### 3. **Use safety settings apropriados**
```python
from vertexai.generative_models import HarmCategory, HarmBlockThreshold

safety_settings = {
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
}
```

### 4. **Caching para regula√ß√µes frequentes**
```python
# Vertex AI Caching (reduz custo + lat√™ncia)
from vertexai.preview import caching

# Cache de regula√ß√£o LGPD (usada em m√∫ltiplas an√°lises)
cached_lgpd = caching.CachedContent.create(
    model_name="gemini-1.5-flash-002",
    system_instruction="Voc√™ √© especialista em LGPD",
    contents=[lgpd_full_text],  # Lei 13.709/2018 completa
    ttl="3600s"  # Cache por 1 hora
)

# Uso do cache
model = GenerativeModel.from_cached_content(cached_lgpd)
response = model.generate_content("Analise este processo contra LGPD...")
# ‚úÖ Economia: ~50% custo + lat√™ncia reduzida
```

---

**ComplianceEngine Platform** - 100% Google Cloud + Vertex AI üöÄ
