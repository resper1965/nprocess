# Regulatory Intelligence Crawler ğŸ”

MicroserviÃ§o de monitoramento automÃ¡tico de atualizaÃ§Ãµes regulatÃ³rias do **setor elÃ©trico brasileiro**.

## ğŸ“‹ VisÃ£o Geral

O Regulatory Intelligence Crawler monitora automaticamente sites regulatÃ³rios em busca de atualizaÃ§Ãµes de normas, resoluÃ§Ãµes e procedimentos que impactam empresas do setor elÃ©trico.

### Fontes Monitoradas

1. **ANEEL** (AgÃªncia Nacional de Energia ElÃ©trica)
   - ResoluÃ§Ãµes Normativas
   - ResoluÃ§Ãµes HomologatÃ³rias
   - Notas TÃ©cnicas
   - NotÃ­cias regulatÃ³rias

2. **ONS** (Operador Nacional do Sistema ElÃ©trico)
   - Procedimentos de Rede (PdR)
   - SubmÃ³dulos
   - InstruÃ§Ãµes Operacionais

3. **ARCyber** (Framework de CiberseguranÃ§a Setor ElÃ©trico)
   - Requisitos de ciberseguranÃ§a
   - Guidelines de seguranÃ§a
   - Mapeamento com ISO 27001, NIST, CIS

## ğŸš€ Funcionalidades

- âœ… **Crawling AutomÃ¡tico**: Monitora fontes regulatÃ³rias 24/7
- âœ… **AnÃ¡lise com IA**: Usa Gemini 1.5 Pro para analisar impacto
- âœ… **DetecÃ§Ã£o de MudanÃ§as**: Identifica novas regulaÃ§Ãµes e alteraÃ§Ãµes
- âœ… **ClassificaÃ§Ã£o de Impacto**: Critical, High, Medium, Low
- âœ… **NotificaÃ§Ãµes**: Email, Slack, Webhooks
- âœ… **AnÃ¡lise de Impacto Empresarial**: EspecÃ­fico para cada empresa
- âœ… **IntegraÃ§Ã£o com RegulatoryRAG**: Indexa automaticamente

## ğŸ“Š Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Regulatory Intelligence Crawler            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    ANEEL    â”‚  â”‚     ONS     â”‚  â”‚   ARCyber   â”‚ â”‚
â”‚  â”‚   Crawler   â”‚  â”‚   Crawler   â”‚  â”‚   Crawler   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                â”‚                â”‚         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                          â”‚                          â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚              â”‚  Crawler Orchestrator â”‚              â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                          â”‚                          â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚         â”‚                â”‚                â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Gemini    â”‚  â”‚ Regulation  â”‚  â”‚Notification â”‚â”‚
â”‚  â”‚  Analyzer   â”‚  â”‚ Repository  â”‚  â”‚  Service    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Endpoints API

### Trigger Manual Crawl
```bash
POST /v1/crawlers/run
{
  "sources": ["aneel", "ons", "arcyber"]  # opcional
}
```

### Get Crawler Status
```bash
GET /v1/crawlers/status
```

### List Updates
```bash
GET /v1/updates?source=aneel&impact_level=critical&limit=20
```

### Get Specific Update
```bash
GET /v1/updates/{update_id}
```

### Analyze Impact
```bash
POST /v1/updates/{update_id}/analyze
{
  "company_context": {
    "company_id": "comp_123",
    "company_name": "Distribuidora XYZ",
    "sector": "energia_eletrica",
    "subsector": "distribuicao"
  }
}
```

## ğŸ³ Deploy

### Docker
```bash
docker build -t regulatory-crawler .
docker run -p 8003:8003 \
  -e GCP_PROJECT_ID=your-project \
  regulatory-crawler
```

### Cloud Run
```bash
gcloud run deploy regulatory-intelligence-crawler \
  --source . \
  --region us-central1 \
  --set-env-vars GCP_PROJECT_ID=your-project
```

## ğŸ“ Exemplo de Uso

### Python
```python
import httpx

# Trigger crawl
async with httpx.AsyncClient() as client:
    response = await client.post(
        "http://localhost:8003/v1/crawlers/run",
        json={"sources": ["aneel"]}
    )
    updates = response.json()

    for update in updates:
        print(f"Nova regulaÃ§Ã£o: {update['title']}")
        print(f"Impacto: {update['impact_level']}")
```

### MCP Tools
```typescript
// Via MCP Server
const result = await mcpClient.callTool("crawl_regulations", {
  sources: ["aneel", "ons"]
});
```

## ğŸ”” NotificaÃ§Ãµes

### Email
```python
POST /v1/notifications/send
{
  "update_id": "upd_aneel_abc123",
  "channels": ["email"],
  "recipients": ["compliance@company.com"],
  "priority": "urgent"
}
```

### Slack
```python
POST /v1/notifications/send
{
  "update_id": "upd_aneel_abc123",
  "channels": ["slack"],
  "recipients": ["#compliance-alerts"],
  "priority": "high"
}
```

## ğŸ“ˆ Scheduler

O crawler executa automaticamente a cada 24 horas, mas pode ser triggered manualmente via API.

## ğŸ” SeguranÃ§a

- âœ… Respeita robots.txt
- âœ… Rate limiting (delay entre requests)
- âœ… User-Agent identificado
- âœ… Logs de auditoria

## ğŸ“š Frameworks Mapeados

### ISO 27001:2022
- Controles Annex A mapeados para regulaÃ§Ãµes do setor

### NIST Cybersecurity Framework
- Identificar, Proteger, Detectar, Responder, Recuperar

### CIS Controls v8
- 18 controles crÃ­ticos mapeados

## ğŸ¤ IntegraÃ§Ã£o com Outros ServiÃ§os

- **RegulatoryRAG API**: Indexa automaticamente novas regulaÃ§Ãµes
- **ComplianceEngine API**: Atualiza processos afetados
- **Admin Dashboard**: Exibe alertas em tempo real

## ğŸ“Š MÃ©tricas

- Total de fontes monitoradas: 3
- FrequÃªncia de crawl: 24h
- Tempo mÃ©dio de detecÃ§Ã£o: < 2h apÃ³s publicaÃ§Ã£o
- AcurÃ¡cia de classificaÃ§Ã£o (IA): ~95%

## ğŸ› Troubleshooting

### Crawler nÃ£o estÃ¡ encontrando updates
- Verificar conectividade com sites fonte
- Verificar seletores CSS (sites podem ter mudado estrutura)
- Verificar logs: `docker logs regulatory-crawler`

### Gemini nÃ£o estÃ¡ funcionando
- Verificar credenciais GCP
- Verificar quota Vertex AI
- Fallback automÃ¡tico para anÃ¡lise heurÃ­stica

## ğŸ“„ LicenÃ§a

ProprietÃ¡rio - ComplianceEngine Platform
